---
title: Glossary
weight: 2
license:
  - name: Creative Commons Attribution-ShareAlike 3.0
    url: https://creativecommons.org/licenses/by-sa/3.0/legalcode
---
### *Updated 27th April 2021*

 <a href="#A">A</a>  <a href="#B">B</a> <a href="#C">C</a>   <a href="#D">D</a> <a href="#E">E</a> <a href="#F">F</a> <a href="#G">G</a>  <a href="#H">H</a> <a href="#I">I</a>  J <a href="#L">L</a> <a href="#M">M</a> <a href="#N">N</a>   <a href="#O">O</a>   <a href="#P">P</a>     <a href="#Q">Q</a>  <a href="#R">R</a>    <a href="#S">S</a>   <a href="#T">T</a>       <a href="#U">U</a>   <a href="#V">V</a>   <a href="#W">W</a>      <a href="#X">X</a>  Y   <a href="#Z">Z</a>        

This page features words and acronyms that are used by people in the effective altruism community, but are not as common outside the community. EA organisations do not appear in this glossary, but many organisations are listed <a target="_blank" href="/learn/orgs">here</a>.

If you’d like to suggest more words or acronyms, or suggest improved definitions or links, please <a target="_blank" href="/contact">contact us</a>. 

<a name="A"></a>

# A

<a target="_blank" href="https://ai-alignment.com/clarifying-ai-alignment-cec47cd69dd6">AI Alignment Problem</a> - The problem of building powerful Artificial Intelligence systems that have goals that are aligned with their operators. 

<a target="_blank" href="https://en.wikipedia.org/wiki/Analysis_paralysis">Analysis Paralysis</a> - When overthinking a situation results in no decision being made and no action being taken, due to fear of consequences of taking the wrong action, or belief that a better solution may be found.

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/artificial-intelligence/">Artificial Intelligence (AI)</a> - Refers to the capability of machines to perform intellectual tasks, such as recognizing objects, forming plans to achieve goals and making predictions.

<a target="_blank" href="https://wiki.lesswrong.com/wiki/Artificial_general_intelligence">Artificial General Intelligence (AGI)</a> -  A machine capable of behaving intelligently over a wide range of domains, similar to how a human can perform a wide variety of tasks. This is in contrast to narrow AI, which is a machine capable of intellectual tasks in a narrow domain. 

<a target="_blank" href="https://wiki.lesswrong.com/wiki/Astronomical_waste">Astronomical waste</a> - A description of the opportunities that we miss out on by not colonising the universe. 

<a name="B"></a>

# B

<a target="_blank" href="https://en.wikipedia.org/wiki/Bayesian_probability">Bayesian probability</a> - The level of certainty of, or confidence in, an idea or outcome. 

<a name="C"></a>

# C

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/career-capital/">Career capital</a> - The collection of skills, connections, and credentials that allow a person to have an impact in their job. 

<a target="_blank" href="https://www.effectivealtruism.org/articles/understanding-cause-neutrality/">Cause-indifference (or cause neutrality)</a> - Selecting a cause area based on an impartial assessment of the impact of working on that cause area. In contrast to having a "pet cause". 

<a target="_blank" href="https://causeprioritization.org/Cause_prioritization">Cause prioritisation</a> - The process of prioritising causes. In EA this is often done according to their scale (how much good or bad they do), their neglectedness (how few resources people are already putting towards this), and their tractability (how easy they are to improve).

<a target="_blank" href="https://www.effectivealtruism.org/articles/moral-progress-and-cause-x/">Cause-X</a> -  A cause that's one of the most important moral problems of our time that we haven’t yet realised the importance of. 

<a target="_blank" href="https://conceptually.org/concepts/cognitive-biases">Cognitive biases</a> - Habits or shortcuts of thinking that can produce misleading or inaccurate conclusions, often unconscious to the thinker. E.g., our inclination to favour evidence that confirms what we already believe, or our irrational resistance to being changed by new evidence are both examples of cognitive biases that are very common barriers to rational progress.

<a target="_blank" href="https://conceptually.org/concepts/cognitive-dissonance-theory">Cognitive Dissonance</a> - The discomfort we feel when holding two or more conflicting beliefs. E.g., a meat eater who believes they are a moral person, yet thinks it is wrong to kill animals, may experience cognitive dissonance and change one of their beliefs. 

<a target="_blank" href="https://www.effectivealtruism.org/articles/prospecting-for-gold-owen-cotton-barratt/#comparative-advantage">Comparative advantage</a> - The idea that some people or groups are better placed than others to perform certain tasks, even if they are worse at that task in absolute terms. This can be applied to the level of countries (e.g., Kazakhstan has a comparative advantage in the production of Potassium) down to individuals in the EA community, e.g., the EA community has a lot of mathematicians, so Kate’s comparative advantage within the EA community might be managing staff, even though she is better at maths than management. 

<a name="consequentialism"></a> <a target="_blank" href="https://concepts.effectivealtruism.org/concepts/consequentialism/">Consequentialism</a> - The view that the moral status of an act (how good or bad it is) is determined solely by the consequences of this act. <a target="_blank" href="https://www.utilitarianism.net/">Utilitarianism</a> is one type of consequentialism.  See ‘Deontology’ and ‘Virtue Ethics’ for some opposing views. 

<a target="_blank" href="https://conceptually.org/concepts/coordination-problems">Coordination Problem</a> - A problem that requires several people (or groups of people) to coordinate to reach the best outcome. <a target="_blank" href="https://conceptually.org/concepts/coordination-problems">The prisoner’s dilemma</a> is a famous example of a coordination problem. An EA example: People see that there is a skill that is neglected in the EA community, so they learn that skill. If too many people take this action the skill becomes oversupplied, but if we are able to coordinate we may fill all the skill shortages over time. 

<a target="_blank" href="https://forum.effectivealtruism.org/posts/etvgLwj59Bs74cuxX/cosmopolitanism">Cosmopolitanism</a> - An inclusive view of the world that sees the interests of human beings of all nationalities as having equal importance. 

<a target="_blank" href="http://www.harvardea.org/terms">Cost-effectiveness</a> - The cost-effectiveness of an activity refers to its impact per amount of money it requires. For example, the cost-effectiveness of some global health charities can be measured by the number of disability adjusted life years (DALYs) averted per $10,000.

<a target="_blank" href="https://en.wikipedia.org/wiki/Cost-effectiveness_analysis">Cost-effectiveness analysis (CEA)/ Cost-effectiveness estimate (CEE)</a> - An analysis of the costs and outcomes of an intervention or course of action, for example calculating a cost per death averted. 

<a target="_blank" href="https://conceptually.org/concepts/counterfactual-thinking">Counterfactual Reasoning</a> - Comparing the expected outcome of an action that was taken to what would have happened in an alternative situation where the action was not taken. 

<a target="_blank" href="https://conceptually.org/concepts/signalling-and-countersignalling">Counter-signalling</a> - A type of signalling behaviour that displays a certain trait by acting in a contradictory manner. For example, being rich enough that displaying your wealth becomes unnecessary because people already know you can afford to, or being good enough friends that you can make disparaging comments confidently aware that the friend knows you are joking. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/credences/">Credence(s)</a> - Degree of confidence or probability that a given proposition is true.

<a name="crucial"></a> <a target="_blank" href="https://concepts.effectivealtruism.org/concepts/the-importance-of-crucial-considerations/">Crucial Considerations</a> - Information that has the potential to radically change your view on a topic or action, e.g., whether insects are capable of suffering is a crucial consideration in determining the scale of wild animal suffering.  

<a name="D"></a>

# D

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/decision-theory">Decision theory</a> - The study of how to rationally choose actions or strategies based on your beliefs about the world and what you value. 

<a target="_blank" href="https://www.effectivealtruism.org/articles/crucial-considerations-and-wise-philanthropy-nick-bostrom/#should-i-vote-in-the-national-election">Deliberation ladder</a> - A sequence of [crucial considerations](#crucial) regarding the same high-level subgoal, where the considerations hold in opposing directions. E.g., when asking the question “should I vote?”, your ladder could consist of “yes, I want to put a good politician in office”, “but my vote is unlikely to make a difference”, “but it could be a close election then I should vote”, “but if it is close then perhaps the candidates are of similar quality”, etc. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/deontology/">Deontology</a> - A group of moral rules or duties held as valuable irrespective of their effect or consequences. E.g., a deontological rule could be “do not kill another person”, which would mean it would be wrong to kill even if there were good consequences, e.g., if the person was about to murder other people. See ‘[Consequentialism](#consequentialism)’ for an opposing view.

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/diminishing-returns/">Diminishing returns or value </a>- A decrease in the marginal value of an action or process as the amount of work that is put in increases. E.g., if a country of 20 million people has no vaccines for a common illness, providing 1 million vaccines for their most vulnerable citizens could be highly valuable, however, providing 1 million vaccines when they already have 19 million vaccines will be significantly less valuable.  

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/direct-work/">Direct Work</a> - Spending time/effort directly on a problem. 

<a name="daly"></a> <a target="_blank" href="https://www.who.int/healthinfo/global_burden_disease/metrics_daly/en/">Disability-Adjusted Life Year (DALY)</a> - A measure of disease burden that is equivalent to one lost year of healthy life. DALYs take into account harm due to death, and harm due to disability. See also [HALY](#haly) and [QALY](#qaly). 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/discounting-the-future/">Discounting (or time discounting)</a> - The idea that goods have less value in the future than they do now. E.g. you might prefer to be given $100 today over being given $150 next year.

Drowning Child - A thought experiment by Peter Singer that argues that we ought to value a human life over material possessions irrespective of geographical distance. 
More information: <a target="_blank" href="https://www.youtube.com/watch?v=9EHnUsV1J2M">Video</a>, <a target="_blank" href="https://www.utilitarian.net/singer/by/199704--.htm">Text</a>.

<a target="_blank" href="https://conceptually.org/concepts/dual-processing-theory">Dual process theory (System 1 and System 2)</a> - Two methods of decision-making: System 1 thinking is intuitive, rapid, automatic, subconscious and emotional. System 2 thinking is deliberate, slow, logical and can involve using data. 

<a name="E"></a>

# E

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/earning-to-give/">Earning to give (ETG)</a> -  Aiming for a high-paying job/career in order to be able to donate a larger amount to charity. 

<a target="_blank" href="https://en.wikipedia.org/wiki/Economies_of_scale">Economies of scale</a> - The cost advantages gained from the decrease in cost per unit output resulting from an increase in the scale of operations. 

<a target="_blank" href="https://www.facebook.com/groups/EffectiveAnimalAdvocacy/about/">Effective Animal Advocacy (EAA)</a> - A branch of EA focused on animal rights and welfare. 

<a target="_blank" href="https://conceptually.org/concepts/efficient-markets/">Efficient market hypothesis</a> - The hypothesis that if all participants in a market have the same information, values and behave rationally, all assets will be priced “correctly”. In other words, it is impossible to ‘beat the market’ by finding undervalued goods, or selling stocks at a higher price than they’re worth. Non-profits are less likely to be within an efficient market as many donors do not donate to maximise the outcome of their donation. 

<a target="_blank" href="https://www.merriam-webster.com/dictionary/epistemic">Epistemic</a> - Relating to knowledge or to the degree of its validation.

<a target="_blank" href="https://en.wikipedia.org/wiki/Epistemic_humility">Epistemic humility</a> - An awareness of the limits of one’s knowledge and one’s ability to acquire knowledge.

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/epistemology/">Epistemology</a> - The study of knowledge and how we form justified beliefs. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/ethics">Ethics</a> - The study of what is good, what is right and what is valuable. Includes the abstract study of defining ‘the good’, and what moral value consists in, as well as the application of ethical norms in society - what we ought to do and how ought we behave.

<a name="existentialrisk"></a> <a target="_blank" href="https://concepts.effectivealtruism.org/concepts/existential-risks/">Existential risk or x-risk</a> - Processes or events that would either result in the extinction of humanity or would permanently curtail  humanity’s future potential.


<a name="expectedvalue"></a> <a target="_blank" href="https://concepts.effectivealtruism.org/concepts/expected-value-theory/">Expected value</a> - A way of evaluating an option based on the value of each possible outcome multiplied by the probability of that outcome occurring, giving the probability-weighted average value of all possible outcomes of that option.

<a target="_blank" href="https://conceptually.org/concepts/explore-or-exploit/">Explore/Exploit tradeoff</a> - The tradeoff between using the information or skills you have now (‘exploiting’), or learning more (‘exploring’). E.g., a person seeking a high-impact career may have to weigh up taking a known path they believe to be high-impact, or learning more to find out if there is a higher impact path available. 

<a name="F"></a>

# F

<a target="_blank" href="https://www.effectivealtruism.org/articles/prospecting-for-gold-owen-cotton-barratt/">Fat-tailed distributions</a> (also called heavy-tailed distributions) - Probability distributions, where one tail decreases towards zero more slowly than if it was a normal bell shaped distribution. E.g. the probability distribution of impact across global health interventions is fat-tailed because the most effective interventions are many times more effective than the average, so most of the overall impact comes from these extremely effective interventions.

<a target="_blank" href="https://www.effectivealtruism.org/get-involved/take-the-founders-pledge/">Founders pledge</a> - Commitment by start-up founders to give a percentage of their future exit or liquidity event earnings to the high-impact charities of their choice.

<a target="_blank" href="https://en.wikipedia.org/wiki/Fungibility">Fungibility</a> - The property of a good or a commodity whose individual units are essentially interchangeable, and each of its parts is indistinguishable from another part. E.g., cash is fungible as all $10s are the same. 

<a target="_blank" href="https://blog.givewell.org/2018/02/13/revisiting-leverage/">Funging</a> - Crowding out a particular project with funding that would have otherwise come from elsewhere. 

<a name="G"></a>

# G

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/global-catastrophic-risks/">Global catastrophic risks (GCRs)</a> - All risks with the potential to cause serious harm on a global scale. Includes <a target="_blank" href="https://concepts.effectivealtruism.org/concepts/existential-risks/">existential risks</a>, but is not limited to them. Catastrophic risks that may not threaten human existence outright include political instability leading to increased warfare, or mass deaths from disease, climate change or geo-engineering.

<a target="_blank" href="https://www.lesswrong.com/posts/YtvZxRpZjcFNwJecS/the-importance-of-goodhart-s-law">Goodhart's law</a> - An adage named after economist Charles Goodhart: "When a measure becomes a target, it ceases to be a good measure."

<a target="_blank" href="https://www.givingwhatwecan.org/pledge/">GWWC pledge (Giving What We Can pledge)</a> - A commitment to giving at least 10% (or 1% for students) of your income to the organisations that you think can do the most good with it.

<a name="H"></a>

# H

<a name="haly"></a> <a target="_blank" href="https://concepts.effectivealtruism.org/concepts/measuring-healthy-life-years/">Health adjusted life year (HALY)</a> - A combined measure of mortality (death) and morbidity (level of ill-health/wellbeing) to quantify the burden of a disease. (see also [DALY](#daly) and [QALY](#qaly)). 

<a target="_blank" href="https://www.effectivealtruism.org/articles/prospecting-for-gold-owen-cotton-barratt/">Heavy-tailed distributions</a> (also called fat tailed distributions) - Probability distributions, where one tail decreases towards zero more slowly than if it was a normal bell shaped distribution. E.g., the probability distribution of impact across global health interventions is heavy-tailed because the most effective interventions are many times more effective than the average, so most of the overall impact comes from these extremely effective interventions.

<a target="_blank" href="https://www.merriam-webster.com/dictionary/hedonic">Hedonic</a> - relating to or characterised by pleasure (in the broad sense of all pleasant feelings). 

<a target="_blank" href="https://en.wikipedia.org/wiki/Hedonic_treadmill">Hedonic treadmill</a> - The tendency of the human mind to adapt back to a stable set point of happiness in spite of positive or negative experiences/changes in life. 

<a target="_blank" href="https://wiki.lesswrong.com/wiki/Hedon">Hedons</a> - The unit philosophers use to quantify pleasure. Hedons are abstract units with no standardised metric.

<a target="_blank" href="https://conceptually.org/concepts/heuristics">Heuristics</a> - Mental shortcuts we use to make decisions. Using ‘common sense’ is a heuristic that we use to determine an answer without searching comprehensively for all the facts ourselves. E.g., the availability heuristic: if events are easier to recall, our brains assume that they’re more likely to occur. 

<a target="_blank" href="http://www.hpmor.com/#content">H.P.M.O.R. (Harry Potter and the Methods of Rationality)</a> - Eliezer Yudkowsky‘s epic Harry Potter fanfiction that rewrites the story on the premise of Harry understanding cognitive biases and logical fallacies. 

<a name="I"></a>

# I

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/importance-neglectedness-tractability/">Importance,Tractability, Neglectedness (ITN)</a> OR Scale, Neglectedness, Solvability (SNS) - a framework used within the EA community to decide which cause areas or interventions are likely to be more promising to focus on. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/information-hazards/">Information hazard</a> - Risks that arise when the dissemination or potential dissemination of  true information can cause harm. E.g., the genetic sequence of a lethal pathogen or a blueprint  for making a thermonuclear weapon.

# J

<a name="L"></a>

# L

<a target="_blank" href="https://blog.givewell.org/2018/02/13/revisiting-leverage/">Leveraging donations</a> - The influence of donations on how others (other donors, governments, or the private sector) allocate their funds. E.g., if a charity has the money to pay for the distribution of deworming tablets, this influences pharmaceutical companies to donate the tablets. 

<a target="_blank" href="https://en.wikipedia.org/wiki/Light_cone">Light cone</a> - The “forward light cone” contains the parts of space-time that we can theoretically influence according to the theory of relativity. We can’t influence the past, nor can we influence far off galaxies in the near future because we are unable to send signals faster than the speed of light. Usually “the forward light cone” can be interpreted as “the future”.

<a target="_blank" href="http://www.compressingreality.com/Utility-Log-Income/">Log of consumption/income</a> - The natural logarithm (log) is a mathematical function that is the inverse of an exponential. The relationship between increased income and benefits is often assumed to be logarithmic; increasing a poor person’s income by a set amount has a much greater impact than increasing a rich person’s income by the same amount. Therefore, the benefits are proportional to the log of the increase in income. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/the-long-term-future/">Long term future (LTF)</a> - More than 100 years into the future, often used in relation to the millions or billions of years that humans and their descendents could live. 

<a name="M"></a>

# M

<a target="_blank" href="https://en.wikipedia.org/wiki/Machine_learning">Machine Learning (ML)</a> - The study of algorithms and models used by computer systems to perform specific tasks without explicit instructions. 

<a target="_blank" href="https://conceptually.org/concepts/marginal-thinking">Marginal thinking</a> - The weighing of value of additional resources, given their relative value to the existing resources held. E.g. getting one banana when you only have one to start with is a more valuable addition than if you started with one million bananas. Marginal thinking helps address the question ‘where will my donation do the most good?’

<a target="_blank" href="https://nickbostrom.com/existential/risks.html">Maxipok principle (Maximising the Probability of an OK outcome)</a> - A suggested rule of thumb for moral actions, that suggests we should take actions that maximise the probability that we avoid existential disaster.

<a target="_blank" href="https://www.lesswrong.com/posts/JmmA2Mf5GrY9D6nQD/four-focus-areas-of-effective-altruism#Focus_Area_2__Meta_Effective_Altruism">Meta-EA</a> - Focusing on bigger picture effective altruism rather than specific causes, for example building the EA movement, or conducting research to analyse which cause areas the EA movement should work on. 

<a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0022103108001613">Moral circle</a> - The boundary drawn around those entities in the world deemed worthy of moral consideration. 

<a target="_blank" href="https://forum.effectivealtruism.org/tag/moral-circle-expansion-1">Moral Circle Expansion (MCE)</a> - A cause area within the movement focused on expanding people’s empathy to consider all sentient beings. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/moral-patienthood/">Moral patienthood</a> - A description for beings that we should have moral concern for and include in a theory of the good. 

<a target="_blank" href="https://forum.effectivealtruism.org/posts/TwJb75GtbD4LvGiku/1-what-is-moral-realism">Moral realism</a> - A meta-ethical view that moral facts and values exist, and are objective. That is, that moral judgments describe moral facts which are as certain in their own way as mathematical facts.

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/moral-uncertainty/">Moral uncertainty</a> - Uncertainty about whether a moral position is true, such as whether it's wrong to steal, or uncertainty about which ethical theory is correct.    

<a target="_blank" href="https://www.lesswrong.com/posts/2jTQTxYNwo6zb3Kyp/preliminary-thoughts-on-moral-weight">Moral weight</a> - How much value is assigned to a moral patient, or how important we consider the welfare of that being to be. 

<a name="N"></a>

# N

<a target="_blank" href="https://en.wikipedia.org/wiki/Negative_utilitarianism">Negative utilitarianism</a> - A philosophical view that puts greater importance on the reduction of suffering, rather than, or in preference to, the maximising of welfare. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/importance-neglectedness-tractability/">Neglectedness (Uncrowdedness)</a> - A factor to consider in cause prioritisation: A cause area or intervention is neglected if it receives minimal attention or is underfunded. 

<a target="_blank" href="https://plato.stanford.edu/entries/nonidentity-problem/">Non-identity problem</a> - An issue that arises when deciding how to value future lives, whereby a given future life will not be the same life if we take one action as opposed to another. That is, where the action we take or don’t take will affect which specific future person(s) come to exist. On some philosophical views this makes it difficult to compare the outcomes of taking or not taking the action, as even if the life of the person in question will be less good than another life might have been if we had taken a different action, it is hard to say that they have been harmed, as the other option was for them not to exist at all.

<a name="O"></a>

# O

<a target="_blank" href="https://causeprioritization.org/Moral_offset">Offsetting</a> - Compensating for taking an action that may be immoral or harmful by counteracting it in some positive way, for example donating to protect rainforests to offset the carbon emissions of flying, or donating to an animal advocacy organisation to offset consuming meat. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/opportunity-cost/">Opportunity cost</a> - The value of the best alternative action that could be or could have been taken instead of the action being considered. 

<a target="_blank" href="https://conceptually.org/option-value/">Option value</a> - The willingness to pay for, or value, preserving an option for the future, rather than losing that option. 

<a target="_blank" href="https://conceptually.org/concepts/overton-window/">Overton Window</a> - The range of (often social or political) ideas the public is willing to discuss. The Overton Window can shift over time under new social reform movements - where an idea previously considered unacceptable, like animals having rights, moves inside the window of acceptability.

<a name="P"></a>

# P

<a target="_blank" href="https://en.wikipedia.org/wiki/Pascal%27s_mugging">Pascal’s mugging</a> - A thought-experiment demonstrating a problem in expected utility maximization. In one version the mugger, who has forgotten their weapon, promises to return tomorrow with much more money, if you’ll just hand over your wallet. While it is very unlikely that deal will be honoured, the mugger argues back that for any low probability of being able to pay back a large amount of money there exists a finite amount that makes it rational to take the bet. Sometimes used as a criticism of arguments that state we ought to take actions that have a tiny chance of preventing human extinction due to the possible upside of enabling trillions of future sentient lives to come into existence.  

<a target="_blank" href="https://rationalwiki.org/wiki/Pascal%27s_wager">Pascal’s wager</a> - The argument that one should believe in God because the potential gains are infinitely good but the potential losses are insignificant. 

<a target="_blank" href="https://en.wikipedia.org/wiki/Person-affecting_view">Person-affecting views</a> - The idea that an action is only good or bad if it affects someone. This implies that, because non-existence is not harmful, there is no moral obligation to create people. Further reading <a target="_blank" href="https://www.effectivealtruism.org/articles/cause-profile-long-run-future/">here</a>. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/personal-fit/">Personal fit</a> - Defined by 80,000 Hours as your chance of excelling at a job, if you work at it. The implication is that a high degree of personal fit with your work will allow you to have a much higher impact. 

Pond Analogy - A thought experiment by Peter Singer that argues that we ought to value a human life over material possessions irrespective of geographical distance. 
More information: <a target="_blank" href="https://www.youtube.com/watch?v=9EHnUsV1J2M">Video</a>, <a target="_blank" href="https://www.utilitarian.net/singer/by/199704--.htm">Text</a>.

<a target="_blank" href="https://en.wikipedia.org/wiki/Population_ethics">Population ethics</a> - The consideration of how our actions affect who is born and how many people are born in the future.

<a target="_blank" href="https://en.wikipedia.org/wiki/Precautionary_principle">Precautionary principle</a> - A principle suggesting caution should be used when considering an action that has a possibility of harm to the public, especially when there is a lack of scientific evidence to address the safety concerns. 

<a target="_blank" href="https://wiki.lesswrong.com/wiki/Priors">Priors</a> - The beliefs a person holds regarding a fact, hypothesis or consequence, before being presented with new evidence.

<a name="Q"></a>

# Q

<a name="qaly"></a> <a target="_blank" href="https://en.wikipedia.org/wiki/Quality-adjusted_life_year">Quality Adjusted Life Year (QALY)</a> - A measure of the equivalent of years of lived in perfect health. Usually in relation to health care interventions that can improve health and/or extend life. See also [HALY](#haly) and [DALY](#daly).

<a name="R"></a>

# R

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/randomized-controlled-trials/">Randomised control trial (RCT)</a> - A scientific study to gain evidence about the impact of an intervention, by splitting the study participants into randomly assigned treatment or control groups and comparing the outcomes between these groups. 

<a target="_blank" href="https://wiki.lesswrong.com/wiki/Rationality">Rationality</a> - Being based on or agreeable to reason, using logical reasoning in your thinking and decision-making process. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/risk-aversion/">Risk aversion</a> - A preference for the safe option over one that carries a higher risk, even if the higher risk option has a higher [expected value](#expectedvalue).

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/room-for-more-funding/">Room for more funding (RFMF)</a> - A concept used in evaluating charities, where the diminishing returns to funding are used to determine whether an increase in funding will be able to have high impact. If a charity has a large RFMF it can use a large amount of extra money effectively.

<a name="S"></a>

# S

<a target="_blank" href="https://wiki.lesswrong.com/wiki/Suffering_risk">S-risk</a> - Risk of the creation of suffering in the far future on an astronomical scale, vastly exceeding all suffering that has existed on Earth so far.

<a target="_blank" href="https://www.lesswrong.com/posts/PtAuvfG9dgkPFLHbk/measuring-the-sanity-waterline/">Sanity waterline</a> - A metaphor used to describe the level of rationality in our civilisation.

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/importance-neglectedness-tractability/">Scale, Neglectedness, Solvability (SNS)</a>, or Importance,Tractability, Neglectedness (ITN)  - a framework used within the EA community to decide which cause areas or interventions are likely to be more promising to focus on. 

<a target="_blank" href="https://conceptually.org/concepts/scope-insensitivity/">Scope insensitivity</a> - Our inability to intuitively or immediately grasp and act on the difference of scope when dealing with large numbers. Even though a program that saves 200,000 birds is 100 times as impactful as a program that saves 2,000 birds, when surveyed, people don’t offer to donate a commensurate 100 times more. In fact, they barely offer to donate more at all. 

<a target="_blank" href="https://en.wikipedia.org/wiki/Sentience">Sentience</a> - The capacity to feel, perceive or experience.

<a target="_blank" href="https://conceptually.org/concepts/signalling-and-countersignalling">Signalling</a> - Actions that convey information about one person to another. Potential employees might signal to would-be employers, via money and time spent on higher education, their commitment and work ethic. Setting aside 10% of your yearly income for highly-effective giving can signal to others a person’s altruistic values. 

<a target="_blank" href="https://conceptually.org/concepts/of-strawmen-and-steelwomen">Strawman/Steelman</a> - A strawman is a version of an argument that is unnecessarily and deliberately weakened in order to be easily defeated. A steelman is charitably assuming the strongest version of an argument (whether it was presented that strongly or not) so as to engage in a more fruitful debate. 

<a target="_blank" href="https://www.lesswrong.com/posts/tyMdPwd8x2RygcheE/sunk-cost-fallacy">Sunk cost fallacy</a> - A cognitive bias where people continue to honour costs that have already been incurred and cannot be recouped, even if taking a different action would result in more value. See also <a target="_blank" href="https://www.youtube.com/watch?v=vpnxd31y0Fo">this explanation</a>. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/superintelligence/">Superintelligence</a> - An intellect capable of performing nearly all cognitive tasks much better than any human can today. See also the <a target="_blank" href="https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies">book by Nick Bostrom</a>. 

<a target="_blank" href="https://conceptually.org/concepts/dual-processing-theory">System 1 and System 2 (Dual Process Theory)</a> - Two methods of decision-making: System 1 thinking is intuitive, rapid, automatic, subconscious and emotional. System 2 thinking is deliberate, slow, logical and can involve using data.  See also David Kahneman's book <a target="_blank" href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow">Thinking, Fast and Slow</a>.

<a name="T"></a>

# T

<a target="_blank" href="https://en.wikipedia.org/wiki/Tail_risk">Tail Risk</a> - The risk from the possibility of an extreme event. Probability distributions have “tails” that indicate extreme outcomes that are possible, but unlikely to happen. The “tail risk” is the risk of one of these unlikely outcomes. E.g. It is likely that the earth will experience an increase in global temperatures of 2-4°C above pre-industrial levels this century, but there is concerning tail risk of >6°C of warming.  

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/talent-constraints-vs-funding-constraints/">Talent vs Funding Constraints</a> - Whether or not the limiting resource factor for an organisation/cause is needing more labour with certain skills, or needing more money. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/importance-neglectedness-tractability/">Tractability</a> - The level to which we can make progress/traction on a problem. If a problem has low tractability we would not make much progress per unit of time or money. 

<a target="_blank" href="https://www.openphilanthropy.org/blog/some-background-our-views-regarding-advanced-artificial-intelligence/">Transformative Artificial Intelligence (TAI)</a> -  AI that precipitates a transition in society comparable to (or more significant than) the agricultural or industrial revolution.

<a target="_blank" href="https://en.wikipedia.org/wiki/Transhumanism">Transhumanism</a> - A movement that advocates for the transformation of the human condition to enhance intellect and physiology. 

<a target="_blank" href="https://en.wikipedia.org/wiki/Trolley_problem">Trolley problems</a> - A series of thought experiments to determine how we value and make decisions about human life, usually by making us consider whether we should take an action that will result in one person’s death in order to save five other people from death. See <a target="_blank" href="https://www.youtube.com/watch?v=bOpf6KcWYyw">this youtube video</a> for a simple outline. 

<a name="U"></a>

# U

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/unilateralists-curse/">Unilateralists Curse</a> - When a number of altruistically minded people each has the ability to “unilaterally” take an action that would accidentally cause harm to others, the probability that the action will be taken by someone will be higher the more people there are independently choosing whether to take this action. Often used in relation to risks of making information public. E.g., a group of scientists create a new strain of a disease, and have varying opinions of the risk of making their work public. Even if most of the scientists think it is too risky to make the discovery public, the work will be made public if the scientist with the lowest assessment of risk decides it is worth making it public. The more scientists in the group, the larger the chance that one will go public. 

<a target="_blank" href="https://www.effectivealtruism.org/articles/ea-global-2018-ubi/">Universal Basic Income (UBI)</a> - A periodic cash payment delivered to all on an individual basis without means test or work requirement. It is unconditional, automatic and would be considered a basic right. Check out  <a target="_blank" href="https://www.givedirectly.org/basic-income/">GiveDirectly’s UBI research</a>. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/bayes-rule/">Updating (Bayesian revision)</a> - Changing of credences in propositions as a result of receiving new evidence.

<a target="_blank" href="https://www.utilitarianism.net/">Utilitarianism</a> - A consequentialist moral theory that holds well-being as the primary good. Actions that produce more well-being are good, whereas actions that lead to a diminishment of well-being are bad. 

<a target="_blank" href="https://wiki.lesswrong.com/wiki/Utility">Utility</a> - Utility is how much a certain outcome satisfies the preferences of a particular being.

<a target="_blank" href="https://en.wikipedia.org/wiki/Utility_monster">Utility monster</a> - A thought experiment, of a hypothetical ‘monster’ that receives multitudes more units of pleasure per amount of resource than any other being, which functions as a criticism of utilitarianism. 

<a target="_blank" href="https://wiki.lesswrong.com/wiki/Utility">Utils, also known as Utilons</a> - A unit of utility. For utilitarians, a greater number of utils is better.

<a name="V"></a>

# V

<a target="_blank" href="https://en.wikipedia.org/wiki/Value_of_life">Value of a statistical life (VSL)</a> - An economic value used to quantify the benefit of avoiding a fatality. But it is important to realise that this is really a measure of the price of a life, and should not be confused with the <a target="_blank" href="https://forum.effectivealtruism.org/posts/apKTPEcRm6jSFaMya/the-value-of-a-life">true value of a life</a>. 

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/virtue-ethics/">Virtue Ethics</a> - A theory of ethics that puts the acting out of virtues as central to ethical decisions. Rather than only attending to whether or not an action produces a good result (consequentialism) or only if it follows an abstract moral duty (deontology), a virtue ethicist will prioritise the action that expresses a virtue, e.g. because that action would be charitable, benevolent or honest.

<a name="W"></a>

# W

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/measuring-healthy-life-years/">Wellbeing Adjusted Life Year (WALY or WELBY)</a> - An extension of standard quality-adjusted life years ([QALY](#qaly))), or disability adjusted life years ([DALY](#daly)) concept to encompass a broader range of wellbeing measures, not just health. 

<a target="_blank" href="https://www.utilitarianism.net/types-of-utilitarianism#welfarism">Welfarism</a> is the view that only the welfare (also called wellbeing) of individuals determines how good a particular state of the world is. Welfarism is accepted by <a target="_blank" href="https://www.utilitarianism.net/">utilitarianism</a> and many other consequentialist theories.

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/wild-animal-suffering/">Wild Animal Suffering (WAS)</a> - The suffering experienced by non-human animals under natural conditions.

<a name="X"></a>

# X

<a target="_blank" href="https://concepts.effectivealtruism.org/concepts/existential-risks/">X-risk or Existential risk</a> - Processes or events that would either result in the extinction of humanity or would permanently curtail humanity's future potential.

# Y

<a name="Z"></a>

# Z

<a target="_blank" href="https://conceptually.org/concepts/zero-vs-positive-sum">Zero-sum game</a> - A situation where resources are limited, have a finite allocation and cannot be infinitely shared. There’s only so many pieces of the pie, and if I get more, you necessarily get less. It’s a win-lose dynamic, as opposed to positive-sum, where the pie only gets bigger and bigger, and the results are win-win.

<hr>

### [NEXT: Reading Lists](/learn/reading-lists/)

### [BACK: About Effective Altruism](/learn/about-ea/)

<hr>

_If you have suggestions on how to improve this page, please comment or suggest edits on_ <a target="_blank" href="https://docs.google.com/document/d/15YeSNg-1jZSC6nkk7HxHIY5qsqmHqveVuI-Pp5dVgT4/edit?usp=sharing">_this google doc._</a>

<hr>
